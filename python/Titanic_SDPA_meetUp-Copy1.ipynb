{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = center> Titanic - survival probability </h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook is a compilation of the analysis steps described in [**DataCamp**](https://campus.datacamp.com/courses/kaggle-python-tutorial-on-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First quest: \n",
    "Using machine learning and  identify the greatest set of factors (Age, Sex, demographic, status, cabin location, etc.) that had significant impact on survival probability for passengers of the Titanic. Show how you came to your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=center> The data  </h3>\n",
    "\n",
    "\n",
    "Variable | Description\n",
    "-|-\n",
    "PassengerId | Passenger ID\n",
    "Survival | Survival (0 = No; 1 = Yes)\n",
    "Pclass | Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "Name | Name\n",
    "Sex\t| Sex\n",
    "Age\t| Age\n",
    "Sibsp | Number of Siblings/Spouses Aboard\n",
    "Parch | Number of Parents/Children Aboard\n",
    "Ticket | Ticket Number\n",
    "Fare | Passenger Fare\n",
    "Cabin | Cabin Number\n",
    "Embarked | Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the pandas library **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Downloading the data\n",
    "We create 2 data frames, one for training, one for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "# train_url = \"out_test.csv\"  # local name (already has the \"Child\" column)\n",
    "train = pd.read_csv(train_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "# test_url = \"out_train.csv\" # local name\n",
    "test = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the `head` of the train dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the test data frame doesn't have a \"Survived\" columnn, that is for us to predict with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Interrogating the training data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many people actually survived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train[\"Survived\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only ~38% of the people survived. How many of the survivors were women?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train[\"Survived\"][train[\"Sex\"]=='female'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "233 people out of the 324 survivers were women, so gender could be a good predictor. What if you were a child? What was the change of surviving? Well, not as definitive. First we have to create a column on the data structure that discrimiates adults from children."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can initialize a column named \"Child\" like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"Child\"] = float('NaN')\n",
    "print(train[\"Child\"][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will populate it according to the following rule: 1 if Age < 18, 0 if Age >= 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"Child\"][train[\"Age\"]<18] = 1\n",
    "train[\"Child\"][train[\"Age\"]>=18] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got warnings here about using chained indexing, but the column was changed succesfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train[\"Child\"][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can write any data frame to a csv file, for example we could export the train file now, and notice that it has the child column at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"out_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but a better use of the cvs output is to make prediction. For example, we can make a prediction of who would survive by only taking gender in account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_one = test\n",
    "test_one[\"Survived\"] = 0\n",
    "test_one[\"Survived\"][test_one[\"Sex\"]==\"female\"] = 1\n",
    "prediction = pd.DataFrame()\n",
    "prediction[\"PassengerId\"] = test_one[\"PassengerId\"]\n",
    "prediction['Survived']=test_one[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "prediction.to_csv(\"myPrediction_genderOnly.csv\",index=False, quoting=csv.QUOTE_NONNUMERIC) #this seems to be the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning a formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are very useful to do classification on structured data. Here we will feed our data to a tree (actually several trees later on) but first there is some cleaning and formatting that we need to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) There are some missing values, for example \"Age\" and \"Embarked\" were not filled for all the passengers. A common way to deal with missing values on a numerical variable is to fill this spaces with the mean of the values that we do have. We will use the **fillna** fucntion and the **median()** atrribute. For the cathegorical variables, we will use the most common value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Most people embarked in Southampton\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) It is also better to change data from cathegorical format to numerical. We will do this for \"Sex\" and \"Embarked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a little tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add a Decision Tree (DT) here. In order to train the tree, we need to specify what column of our data is the target and what features we will use. We do so by defining the following arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train[\"Survived\"].values\n",
    "features_one = train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_tree_one = tree.DecisionTreeClassifier()\n",
    "my_tree_one = my_tree_one.fit(features_one,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine how well the model did on the train set by checking the *score()* and the list of feature importances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"[Pclass\", \"Sex\", \"Age\", \"Fare]\")\n",
    "print(my_tree_one.feature_importances_)\n",
    "print(my_tree_one.score(features_one,target))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From here we were able to see that the \"Fare\" is the most important feature, that is, we can find a good value (or theshold) on the \"Fare\" column that will allow us to classify who would survive or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a prediction with one DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To asses our model, we have to make a prediction for the survival rates, using the \"test\" set, which is a clean set that our model hasn't been exposed to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the nans in \"Fare\" with the median of the corresponding Passanger class (Pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Fare1 = test[\"Fare\"][test.Pclass == 1].mean()\n",
    "Fare2 = test[\"Fare\"][test.Pclass == 2].mean()\n",
    "Fare3 = test[\"Fare\"][test.Pclass == 3].mean()\n",
    "print(Fare1, Fare2, Fare3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(test[\"Fare\"][(pd.isnull(test.Fare)) & (test.Pclass == 1)])\n",
    "print(test[\"Fare\"][(pd.isnull(test.Fare)) & (test.Pclass == 2)])\n",
    "print(test[\"Fare\"][(pd.isnull(test.Fare)) & (test.Pclass == 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know there is only one missing value for \"Fare\" and we know it's for someone on 3rd class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test.Fare[pd.isnull(test.Fare)] = Fare3\n",
    "test.Fare = test.Fare.fillna(Fare3)\n",
    "# print(test[150:160])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Run all the transformation we ran on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill up missing values on any of the parameters: \n",
    "# \"Pclass\", \"Sex\", \"Age\" and \"Fare\"\n",
    "pd.isnull(test.Pclass).value_counts() # all False\n",
    "\n",
    "pd.isnull(test.Sex).value_counts() # also all False, but this has to be change to numberic\n",
    "test[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\n",
    "test[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "pd.isnull(test.Age).value_counts() #86/418 ~ 20%\n",
    "# pd.isnull(train.Age).value_counts() #177/891 in the original data ~ 19% OK\n",
    "test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n",
    "\n",
    "# pd.isnull(test.Fare).value_counts() # all false now... of course\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Define the array of relevan relevant features to be passed to our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = test[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the prediction applying our model \"my_tree_one\" to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_prediction = my_tree_one.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(my_solution.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_solution.to_csv(\"my_solution_DT_one.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted this and I got 0.71770 in Kaggle, they say it's not the best submission of my team, so keep on trying!!! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
